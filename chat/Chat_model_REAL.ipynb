{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import string\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "import math\n",
    "import torch.utils.data as data\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_letters = string.printable\n",
    "n_letters = len(all_letters)\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "def linesToTensor(lines):\n",
    "    line_length = 15000\n",
    "    if max([ len(line) for line in lines]) < line_length:\n",
    "        line_length = max( [len(line) for line in lines] )\n",
    "    #line_length = max( [len(line) for line in lines] )\n",
    "    #xx = [max(len(line)-15000,0) for line in lines]\n",
    "    #print float(np.sum(xx)) / float(np.sum([len(line) for line in lines]))\n",
    "    tensor = torch.zeros(len(lines), line_length, n_letters)\n",
    "    for b, line in enumerate(lines): \n",
    "        line = line[:15000]\n",
    "        for li, letter in enumerate(line):\n",
    "            tensor[b][li + line_length - len(line)][letterToIndex(letter)] = 1\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangModel(nn.Module):\n",
    "    def __init__(self, preTrained='True', input=100):\n",
    "        super(LangModel, self).__init__()\n",
    "\n",
    "        # Language Model\n",
    "        self.lang = nn.LSTM(input, 128, 3, batch_first=True) \n",
    " \n",
    "        # Output \n",
    "        self.output = nn.Linear(128, 2)\n",
    "        n = self.output.in_features * self.output.out_features\n",
    "        self.output.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        self.output.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text):\n",
    "        text.cuda()\n",
    "        h0 = ( Variable(torch.zeros(3, text.size(0), 128)).cuda(),  Variable(torch.zeros(3, text.size(0), 128)).cuda())\n",
    "\n",
    "        lang_feature, hn = self.lang(text, h0 )\n",
    "        lang_feature = lang_feature[:,-1,:]\n",
    "\n",
    "        pred = self.output(lang_feature)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_data='./exp_chat/{}.npy'.format(game_id)\n",
    "chat_arr=np.load(chat_data)\n",
    "window_text=[]\n",
    "for i in range(len(chat_arr)):\n",
    "    temp=''\n",
    "    for idx in range(7):\n",
    "        if i+idx<len(chat_arr):\n",
    "            temp+=chat_arr[i+idx]\n",
    "    window_text.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=linesToTensor(window_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2056, 2700, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class chat_ds(data.Dataset):\n",
    "    def __init__(self,game_id):\n",
    "        self.window_text=[]\n",
    "        #####game id 전체로 바꿀것##############\n",
    "        chat_data='./exp_chat/{}.npy'.format(game_id)\n",
    "        chat_arr=np.load(chat_data)\n",
    "        #window_text=np.zeros([len(text)])\n",
    "        for i in range(len(chat_arr)):\n",
    "            temp=''\n",
    "            for idx in range(7):\n",
    "                if i+idx<len(chat_arr):\n",
    "                    temp+=chat_arr[i+idx]\n",
    "            window_text.append(temp)\n",
    "        self.text=linesToTensor(window_text)\n",
    "\n",
    "        with open('../tsvt/ocr/hi_time.json','r') as f:\n",
    "            labels=json.load(f)\n",
    "\n",
    "        label=labels[game_id]\n",
    "        \n",
    "        self.label_gt=torch.zeros((len(text),))\n",
    "        for (x,y) in label:\n",
    "            start=int(x.split(':')[0])*60+int(x.split(':')[1])\n",
    "            end=int(y.split(':')[0])*60+int(y.split(':')[1])\n",
    "            for i in range(start,end+1):\n",
    "                self.label_gt[i]=1\n",
    "        self.label_gt=self.label_gt.long()\n",
    "    def __len__(self):\n",
    "        return len(self.label_gt)\n",
    "    def __getitem__(self,index):\n",
    "        return self.text[index],self.label_gt[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_id='102844212428895431'\n",
    "a=chat_ds(game_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=torch.utils.data.DataLoader(a,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### model load #####\n",
    "model=LangModel().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#train set\n",
    "model.train()\n",
    "count=0\n",
    "for inputs,labels in (loader):\n",
    "    print(count)\n",
    "    count+=1\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 0.1)\n",
    "    optimizer.zero_grad()\n",
    "    output=model(inputs)\n",
    "    \n",
    "    loss=criterion(output,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "[0/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[1/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[2/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[3/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[4/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[5/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[6/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[7/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[8/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[9/21]\n",
      "tensor(0, device='cuda:0')\n",
      "[10/21]\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1201, device='cuda:0') tensor(401, device='cuda:0')\n",
      "[11/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1301, device='cuda:0') tensor(401, device='cuda:0')\n",
      "[12/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1401, device='cuda:0') tensor(469, device='cuda:0')\n",
      "[13/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1501, device='cuda:0') tensor(569, device='cuda:0')\n",
      "[14/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1601, device='cuda:0') tensor(669, device='cuda:0')\n",
      "[15/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1701, device='cuda:0') tensor(769, device='cuda:0')\n",
      "[16/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1801, device='cuda:0') tensor(869, device='cuda:0')\n",
      "[17/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(1901, device='cuda:0') tensor(871, device='cuda:0')\n",
      "[18/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(2001, device='cuda:0') tensor(891, device='cuda:0')\n",
      "[19/21], prec:0, recall:0, f1:429496729500\n",
      "tensor(0, device='cuda:0')\n",
      "correct, pred, gt tensor(0, device='cuda:0') tensor(2057, device='cuda:0') tensor(924, device='cuda:0')\n",
      "[20/21], prec:0, recall:0, f1:429496729500\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred_sum = 1\n",
    "gt_sum = 1\n",
    "correct_sum = 0\n",
    "for it, (inputs,labels) in enumerate(loader):\n",
    "    count+=1\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    output=model(inputs)\n",
    "    correct_len, pred_len, gt_len=fmeasure(output,labels)\n",
    "    correct_sum += correct_len\n",
    "    pred_sum += pred_len\n",
    "    gt_sum += gt_len\n",
    "    print(correct_sum)\n",
    "    if it > 10:\n",
    "        precision = correct_sum / float(pred_sum) + 1e-40\n",
    "        recall = correct_sum / float(gt_sum) + 1e-40\n",
    "        f1 = (2*precision*recall / (precision + recall)) * 100\n",
    "        print('correct, pred, gt', correct_sum, pred_sum, gt_sum)\n",
    "        print('[{}/{}], prec:{}, recall:{}, f1:{}'.format(it, len(loader), precision, recall, f1))\n",
    "    else :\n",
    "        print('[{}/{}]'.format(it, len(loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmeasure(output, target):\n",
    "    _, pred = output.t(1, 1, True, True)\n",
    "    pred = pred.view(-1,1)\n",
    "    target = target.view(-1,1)\n",
    "    overlap = ((pred== 1) + (target == 1)).gt(1)\n",
    "    overlap = overlap.view(-1,1)\n",
    "\n",
    "    overlap_len = overlap.data.long().sum()\n",
    "    pred_len = pred.data.long().sum()\n",
    "    gt_len   =  target.data.long().sum()\n",
    "\n",
    "    return overlap_len, pred_len, gt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyein_1.2.0",
   "language": "python",
   "name": "newcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
