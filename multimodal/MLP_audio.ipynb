{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "with open('/home/ubuntu/gangmin/tsvt/multimodal/data/audio_energy_1_normaized.pickle',\"rb\") as f:\n",
    "    energy1 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "with open('/home/ubuntu/gangmin/tsvt/multimodal/label/label.pickle',\"rb\") as f:\n",
    "    label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor key in label.keys():\\n    remain = len(label[key])%7\\n    if remain !=0:\\n        for i in range(7-remain):\\n            for j in range(10):\\n                energy1[key] = np.append(energy1[key],0)\\n            label[key] = np.append(label[key],0)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for key in label.keys():\n",
    "    remain = len(label[key])%7\n",
    "    if remain !=0:\n",
    "        for i in range(7-remain):\n",
    "            for j in range(10):\n",
    "                energy1[key] = np.append(energy1[key],0)\n",
    "            label[key] = np.append(label[key],0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor key in label.keys():\\n    remain = len(label[key])%7\\n    if remain !=0:\\n        print(remain)\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for key in label.keys():\n",
    "    remain = len(label[key])%7\n",
    "    if remain !=0:\n",
    "        print(remain)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train =[102844235753356742, 102844294666422466, 102844341906256529, 102979081290790284, 102844212430271695, 102844401155937960, 102844412704496937, 102844412722519367, 102844235749031358, 102844412709674293, 102844341902586509, 102844235750997440, 102844212431975640, 102844294667995333, 102844341912220311, 102844235747261881, 102844294670551241, 102844412707708209, 102844212430599377, 102844224145685626, 102844401152857762, 102844341908026005, 102844341909598870, 102844283023599703, 102844235753749959, 102844294670026952, 102844212430075086, 102844283027531868, 102844212430927059, 102844212429419722, 102844283025696858, 102844224146472059, 102844412712164667, 102844401153971877, 102844235748310460, 102844412711116088, 102844235752111555, 102844283020453971, 102844294666881219, 102844401152267937, 102844212429944013, 102844294671796427, 102844401151874719, 102844412723567946, 102844294669568199, 102844412709346612, 102844212431779031, 102844212430402768, 102844412711443769, 102844283027925085, 102844235746868664, 102844283023206486, 102844401154168486, 102844212429550795, 102844341907370644, 102844412721339716, 102844294667405508, 102844294674876621, 102844212429288649, 102844401154430631]\n",
    "\n",
    "val = [102844412705545516, 102844401153447587, 102844341912679064, 102844212431320277, 102844212431516886, 102844401152071328, 102844341906977427, 102844212429747404, 102844235747982779, 102844412716686654, 102844294669109446, 102844412722847048, 102844412721012035, 102844401151219358, 102844235746475447, 102844412720618818, 102904869420860038, 102910307641576395, 102844235751783874, 102844224146930812, 102844341905011343, 102844235752963525, 102844235748703677, 102844235749424575, 102844412705217835, 102844412723174729, 102844401153578660, 102844341905404560, 102844412706987311, 102844341906649746]\n",
    "\n",
    "test = [102844412717014335, 102844224148503678, 102844412711836986, 102844401156069033, 102844294670878922, 102844341904683662, 102844412704890154, 102844235746082230, 102844224148896895, 102844294674286796, 102844412708953395, 102844235751390657, 102844212428895431, 102844412717407552, 102844212429092040, 102844412707380528, 102844212430730450, 102844224147717245, 102844412716227901, 102844212431058132, 102844412710001974, 102844412706659630]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import adam\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pd.DataFrame(columns=['audio'])\n",
    "for key in train:\n",
    "    train_X = pd.concat([train_X,pd.DataFrame(energy1[str(key)])],axis=0)\n",
    "\n",
    "train_X = train_X.reset_index()\n",
    "train_X = train_X.drop('index',axis=1)\n",
    "train_X = train_X.drop('audio',axis=1)\n",
    "train_X.columns = ['audio']\n",
    "\n",
    "test_X = pd.DataFrame(columns=['audio'])\n",
    "for key in test:\n",
    "    test_X = pd.concat([test_X,pd.DataFrame(energy1[str(key)])],axis=0)\n",
    "\n",
    "test_X = test_X.reset_index()\n",
    "test_X = test_X.drop('index',axis=1)\n",
    "test_X = test_X.drop('audio',axis=1)\n",
    "test_X.columns = ['audio']\n",
    "\n",
    "val_X = pd.DataFrame(columns=['audio'])\n",
    "for key in val:\n",
    "    val_X = pd.concat([val_X,pd.DataFrame(energy1[str(key)])],axis=0)\n",
    "\n",
    "val_X = val_X.reset_index()\n",
    "val_X = val_X.drop('index',axis=1)\n",
    "val_X = val_X.drop('audio',axis=1)\n",
    "val_X.columns = ['audio']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.DataFrame(columns=['highlight'])\n",
    "for key in train:\n",
    "    temp = pd.DataFrame()\n",
    "    temp['highlight'] = label[str(key)]\n",
    "    \n",
    "    train_y = pd.concat([train_y,temp],axis=0)\n",
    "    \n",
    "train_y = train_y.reset_index()\n",
    "train_y = train_y.drop('index',axis=1)\n",
    "\n",
    "test_y = pd.DataFrame(columns=['highlight'])\n",
    "for key in test:\n",
    "    temp = pd.DataFrame()\n",
    "    temp['highlight'] = label[str(key)]\n",
    "    \n",
    "    test_y = pd.concat([test_y,temp],axis=0)\n",
    "    \n",
    "test_y = test_y.reset_index()\n",
    "test_y = test_y.drop('index',axis=1)\n",
    "\n",
    "val_y = pd.DataFrame(columns=['highlight'])\n",
    "for key in val:\n",
    "    temp = pd.DataFrame()\n",
    "    temp['highlight'] = label[str(key)]\n",
    "    \n",
    "    val_y = pd.concat([val_y,temp],axis=0)\n",
    "    \n",
    "val_y = val_y.reset_index()\n",
    "val_y = val_y.drop('index',axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.array(train_X['audio'].tolist())\n",
    "test_X = np.array(test_X['audio'].tolist())\n",
    "val_X = np.array(val_X['audio'].tolist())\n",
    "train_y = np.array(train_y['highlight'].tolist())\n",
    "test_y = np.array(test_y['highlight'].tolist())\n",
    "val_y = np.array(val_y['highlight'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(len(train_X)//10,10)\n",
    "test_X = test_X.reshape(len(test_X)//10,10)\n",
    "val_X = val_X.reshape(len(val_X)//10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_X = train_X.reshape(len(train_X)//7,7)\n",
    "test_X = test_X.reshape(len(test_X)//7,7)\n",
    "val_X = val_X.reshape(len(val_X)//7,7)\n",
    "train_y = train_y.reshape(len(train_y)//7,7)\n",
    "test_y = test_y.reshape(len(test_y)//7,7)\n",
    "val_y = val_y.reshape(len(val_y)//7,7)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123085"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123085"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(10,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='/home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/'+'{epoch:02d}-{val_loss:.4f}.hdf5',monitor = 'val_loss',verbose=1,save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 123085 samples, validate on 58245 samples\n",
      "Epoch 1/200\n",
      "123085/123085 [==============================] - 5s 42us/step - loss: 0.4846 - accuracy: 0.8164 - val_loss: 0.4743 - val_accuracy: 0.8179\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.47426, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/01-0.4743.hdf5\n",
      "Epoch 2/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4781 - accuracy: 0.8167 - val_loss: 0.4747 - val_accuracy: 0.8179\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.47426\n",
      "Epoch 3/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4775 - accuracy: 0.8168 - val_loss: 0.4739 - val_accuracy: 0.8181\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.47426 to 0.47394, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/03-0.4739.hdf5\n",
      "Epoch 4/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4772 - accuracy: 0.8169 - val_loss: 0.4741 - val_accuracy: 0.8181\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.47394\n",
      "Epoch 5/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4767 - accuracy: 0.8171 - val_loss: 0.4745 - val_accuracy: 0.8180\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.47394\n",
      "Epoch 6/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4764 - accuracy: 0.8170 - val_loss: 0.4731 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47394 to 0.47312, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/06-0.4731.hdf5\n",
      "Epoch 7/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4761 - accuracy: 0.8172 - val_loss: 0.4733 - val_accuracy: 0.8183\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.47312\n",
      "Epoch 8/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4757 - accuracy: 0.8172 - val_loss: 0.4728 - val_accuracy: 0.8183\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.47312 to 0.47282, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/08-0.4728.hdf5\n",
      "Epoch 9/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4755 - accuracy: 0.8172 - val_loss: 0.4731 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.47282\n",
      "Epoch 10/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4754 - accuracy: 0.8173 - val_loss: 0.4731 - val_accuracy: 0.8184\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.47282\n",
      "Epoch 11/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4751 - accuracy: 0.8174 - val_loss: 0.4726 - val_accuracy: 0.8185\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.47282 to 0.47258, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/11-0.4726.hdf5\n",
      "Epoch 12/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4751 - accuracy: 0.8174 - val_loss: 0.4735 - val_accuracy: 0.8186\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.47258\n",
      "Epoch 13/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4748 - accuracy: 0.8176 - val_loss: 0.4725 - val_accuracy: 0.8185\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.47258 to 0.47249, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/13-0.4725.hdf5\n",
      "Epoch 14/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4746 - accuracy: 0.8176 - val_loss: 0.4726 - val_accuracy: 0.8187\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.47249\n",
      "Epoch 15/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4744 - accuracy: 0.8177 - val_loss: 0.4724 - val_accuracy: 0.8186\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.47249 to 0.47241, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/15-0.4724.hdf5\n",
      "Epoch 16/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4744 - accuracy: 0.8177 - val_loss: 0.4724 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.47241 to 0.47235, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/16-0.4724.hdf5\n",
      "Epoch 17/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4744 - accuracy: 0.8177 - val_loss: 0.4724 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.47235\n",
      "Epoch 18/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4743 - accuracy: 0.8177 - val_loss: 0.4727 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.47235\n",
      "Epoch 19/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4742 - accuracy: 0.8179 - val_loss: 0.4728 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.47235\n",
      "Epoch 20/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4740 - accuracy: 0.8179 - val_loss: 0.4724 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.47235\n",
      "Epoch 21/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4739 - accuracy: 0.8178 - val_loss: 0.4726 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.47235\n",
      "Epoch 22/200\n",
      "123085/123085 [==============================] - 5s 42us/step - loss: 0.4738 - accuracy: 0.8178 - val_loss: 0.4722 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.47235 to 0.47223, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/22-0.4722.hdf5\n",
      "Epoch 23/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4739 - accuracy: 0.8180 - val_loss: 0.4726 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.47223\n",
      "Epoch 24/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4735 - accuracy: 0.8180 - val_loss: 0.4726 - val_accuracy: 0.8186\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.47223\n",
      "Epoch 25/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4737 - accuracy: 0.8181 - val_loss: 0.4724 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.47223\n",
      "Epoch 26/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4737 - accuracy: 0.8180 - val_loss: 0.4721 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.47223 to 0.47207, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/26-0.4721.hdf5\n",
      "Epoch 27/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4738 - accuracy: 0.8180 - val_loss: 0.4724 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.47207\n",
      "Epoch 28/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4734 - accuracy: 0.8181 - val_loss: 0.4723 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.47207\n",
      "Epoch 29/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4737 - accuracy: 0.8180 - val_loss: 0.4722 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.47207\n",
      "Epoch 30/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4737 - accuracy: 0.8180 - val_loss: 0.4720 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.47207 to 0.47200, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/30-0.4720.hdf5\n",
      "Epoch 31/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4737 - accuracy: 0.8179 - val_loss: 0.4720 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.47200 to 0.47195, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/31-0.4720.hdf5\n",
      "Epoch 32/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4734 - accuracy: 0.8181 - val_loss: 0.4721 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.47195\n",
      "Epoch 33/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4733 - accuracy: 0.8182 - val_loss: 0.4722 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.47195\n",
      "Epoch 34/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4733 - accuracy: 0.8182 - val_loss: 0.4721 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.47195\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123085/123085 [==============================] - 4s 31us/step - loss: 0.4733 - accuracy: 0.8182 - val_loss: 0.4721 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.47195\n",
      "Epoch 36/200\n",
      "123085/123085 [==============================] - 4s 30us/step - loss: 0.4732 - accuracy: 0.8181 - val_loss: 0.4719 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.47195 to 0.47188, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/36-0.4719.hdf5\n",
      "Epoch 37/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4733 - accuracy: 0.8182 - val_loss: 0.4717 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.47188 to 0.47171, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/37-0.4717.hdf5\n",
      "Epoch 38/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4732 - accuracy: 0.8182 - val_loss: 0.4717 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.47171 to 0.47170, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/38-0.4717.hdf5\n",
      "Epoch 39/200\n",
      "123085/123085 [==============================] - 4s 30us/step - loss: 0.4733 - accuracy: 0.8183 - val_loss: 0.4720 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.47170\n",
      "Epoch 40/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4733 - accuracy: 0.8181 - val_loss: 0.4717 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.47170 to 0.47166, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/40-0.4717.hdf5\n",
      "Epoch 41/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4734 - accuracy: 0.8181 - val_loss: 0.4719 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.47166\n",
      "Epoch 42/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4732 - accuracy: 0.8182 - val_loss: 0.4717 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.47166\n",
      "Epoch 43/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4733 - accuracy: 0.8182 - val_loss: 0.4720 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.47166\n",
      "Epoch 44/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4732 - accuracy: 0.8183 - val_loss: 0.4717 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.47166\n",
      "Epoch 45/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4729 - accuracy: 0.8182 - val_loss: 0.4716 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.47166 to 0.47164, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/45-0.4716.hdf5\n",
      "Epoch 46/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4733 - accuracy: 0.8181 - val_loss: 0.4720 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.47164\n",
      "Epoch 47/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4732 - accuracy: 0.8182 - val_loss: 0.4721 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.47164\n",
      "Epoch 48/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4734 - accuracy: 0.8182 - val_loss: 0.4726 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.47164\n",
      "Epoch 49/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4732 - accuracy: 0.8183 - val_loss: 0.4720 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.47164\n",
      "Epoch 50/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4733 - accuracy: 0.8182 - val_loss: 0.4718 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.47164\n",
      "Epoch 51/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4732 - accuracy: 0.8183 - val_loss: 0.4723 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.47164\n",
      "Epoch 52/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4731 - accuracy: 0.8183 - val_loss: 0.4719 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.47164\n",
      "Epoch 53/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4731 - accuracy: 0.8183 - val_loss: 0.4717 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.47164\n",
      "Epoch 54/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4731 - accuracy: 0.8183 - val_loss: 0.4718 - val_accuracy: 0.8190\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.47164\n",
      "Epoch 55/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4734 - accuracy: 0.8183 - val_loss: 0.4717 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.47164\n",
      "Epoch 56/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4729 - accuracy: 0.8183 - val_loss: 0.4717 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.47164\n",
      "Epoch 57/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4731 - accuracy: 0.8183 - val_loss: 0.4719 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.47164\n",
      "Epoch 58/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4729 - accuracy: 0.8184 - val_loss: 0.4721 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.47164\n",
      "Epoch 59/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4728 - accuracy: 0.8184 - val_loss: 0.4720 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.47164\n",
      "Epoch 60/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4730 - accuracy: 0.8183 - val_loss: 0.4722 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.47164\n",
      "Epoch 61/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4731 - accuracy: 0.8181 - val_loss: 0.4716 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.47164 to 0.47158, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/61-0.4716.hdf5\n",
      "Epoch 62/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4730 - accuracy: 0.8183 - val_loss: 0.4718 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.47158\n",
      "Epoch 63/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4728 - accuracy: 0.8184 - val_loss: 0.4719 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.47158\n",
      "Epoch 64/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4727 - accuracy: 0.8184 - val_loss: 0.4716 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.47158 to 0.47155, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/64-0.4716.hdf5\n",
      "Epoch 65/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4728 - accuracy: 0.8183 - val_loss: 0.4718 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.47155\n",
      "Epoch 66/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4730 - accuracy: 0.8183 - val_loss: 0.4716 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.47155\n",
      "Epoch 67/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4731 - accuracy: 0.8181 - val_loss: 0.4717 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.47155\n",
      "Epoch 68/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4727 - accuracy: 0.8185 - val_loss: 0.4716 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.47155\n",
      "Epoch 69/200\n",
      "123085/123085 [==============================] - 5s 42us/step - loss: 0.4728 - accuracy: 0.8183 - val_loss: 0.4715 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.47155 to 0.47151, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/69-0.4715.hdf5\n",
      "Epoch 70/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4729 - accuracy: 0.8184 - val_loss: 0.4716 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.47151\n",
      "Epoch 71/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4728 - accuracy: 0.8184 - val_loss: 0.4716 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.47151\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4727 - accuracy: 0.8184 - val_loss: 0.4717 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.47151\n",
      "Epoch 73/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4729 - accuracy: 0.8182 - val_loss: 0.4721 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.47151\n",
      "Epoch 74/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4727 - accuracy: 0.8185 - val_loss: 0.4715 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.47151 to 0.47149, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/74-0.4715.hdf5\n",
      "Epoch 75/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4727 - accuracy: 0.8183 - val_loss: 0.4719 - val_accuracy: 0.8189\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.47149\n",
      "Epoch 76/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4729 - accuracy: 0.8183 - val_loss: 0.4719 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.47149\n",
      "Epoch 77/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4727 - accuracy: 0.8183 - val_loss: 0.4720 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.47149\n",
      "Epoch 78/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4726 - accuracy: 0.8185 - val_loss: 0.4717 - val_accuracy: 0.8191\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.47149\n",
      "Epoch 79/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4727 - accuracy: 0.8184 - val_loss: 0.4715 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.47149 to 0.47145, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/79-0.4715.hdf5\n",
      "Epoch 80/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4724 - accuracy: 0.8185 - val_loss: 0.4716 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.47145\n",
      "Epoch 81/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4723 - accuracy: 0.8187 - val_loss: 0.4717 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.47145\n",
      "Epoch 82/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4727 - accuracy: 0.8185 - val_loss: 0.4719 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.47145\n",
      "Epoch 83/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4724 - accuracy: 0.8186 - val_loss: 0.4715 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.47145 to 0.47145, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/83-0.4715.hdf5\n",
      "Epoch 84/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4725 - accuracy: 0.8185 - val_loss: 0.4717 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.47145\n",
      "Epoch 85/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4727 - accuracy: 0.8185 - val_loss: 0.4717 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.47145\n",
      "Epoch 86/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4726 - accuracy: 0.8185 - val_loss: 0.4714 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.47145 to 0.47141, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/86-0.4714.hdf5\n",
      "Epoch 87/200\n",
      "123085/123085 [==============================] - 5s 42us/step - loss: 0.4724 - accuracy: 0.8185 - val_loss: 0.4717 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.47141\n",
      "Epoch 88/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4726 - accuracy: 0.8186 - val_loss: 0.4716 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.47141\n",
      "Epoch 89/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4726 - accuracy: 0.8184 - val_loss: 0.4715 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.47141\n",
      "Epoch 90/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4724 - accuracy: 0.8185 - val_loss: 0.4714 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.47141\n",
      "Epoch 91/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4715 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.47141\n",
      "Epoch 92/200\n",
      "123085/123085 [==============================] - 4s 36us/step - loss: 0.4724 - accuracy: 0.8185 - val_loss: 0.4715 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.47141\n",
      "Epoch 93/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4715 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.47141\n",
      "Epoch 94/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4725 - accuracy: 0.8185 - val_loss: 0.4715 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.47141\n",
      "Epoch 95/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4725 - accuracy: 0.8186 - val_loss: 0.4714 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.47141\n",
      "Epoch 96/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4726 - accuracy: 0.8186 - val_loss: 0.4715 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.47141\n",
      "Epoch 97/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4714 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.47141 to 0.47138, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/97-0.4714.hdf5\n",
      "Epoch 98/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4725 - accuracy: 0.8185 - val_loss: 0.4714 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.47138\n",
      "Epoch 99/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4724 - accuracy: 0.8186 - val_loss: 0.4718 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.47138\n",
      "Epoch 100/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4723 - accuracy: 0.8185 - val_loss: 0.4717 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.47138\n",
      "Epoch 101/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4723 - accuracy: 0.8187 - val_loss: 0.4715 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.47138\n",
      "Epoch 102/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4724 - accuracy: 0.8185 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.47138 to 0.47127, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/102-0.4713.hdf5\n",
      "Epoch 103/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4724 - accuracy: 0.8186 - val_loss: 0.4721 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.47127\n",
      "Epoch 104/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4724 - accuracy: 0.8185 - val_loss: 0.4716 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.47127\n",
      "Epoch 105/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4722 - accuracy: 0.8188 - val_loss: 0.4715 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.47127\n",
      "Epoch 106/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4722 - accuracy: 0.8187 - val_loss: 0.4714 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.47127\n",
      "Epoch 107/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4721 - accuracy: 0.8185 - val_loss: 0.4712 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.47127 to 0.47117, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/107-0.4712.hdf5\n",
      "Epoch 108/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4715 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.47117\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4724 - accuracy: 0.8186 - val_loss: 0.4721 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.47117\n",
      "Epoch 110/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4714 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.47117\n",
      "Epoch 111/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4722 - accuracy: 0.8186 - val_loss: 0.4719 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.47117\n",
      "Epoch 112/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4724 - accuracy: 0.8185 - val_loss: 0.4716 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.47117\n",
      "Epoch 113/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4722 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.47117\n",
      "Epoch 114/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4722 - accuracy: 0.8185 - val_loss: 0.4723 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.47117\n",
      "Epoch 115/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4720 - accuracy: 0.8186 - val_loss: 0.4713 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.47117\n",
      "Epoch 116/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4713 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.47117\n",
      "Epoch 117/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4722 - accuracy: 0.8187 - val_loss: 0.4722 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.47117\n",
      "Epoch 118/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4715 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.47117\n",
      "Epoch 119/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4720 - accuracy: 0.8188 - val_loss: 0.4714 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.47117\n",
      "Epoch 120/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4722 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.47117\n",
      "Epoch 121/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4723 - accuracy: 0.8185 - val_loss: 0.4714 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.47117\n",
      "Epoch 122/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4714 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.47117\n",
      "Epoch 123/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4723 - accuracy: 0.8186 - val_loss: 0.4712 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.47117\n",
      "Epoch 124/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4721 - accuracy: 0.8186 - val_loss: 0.4713 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.47117\n",
      "Epoch 125/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4722 - accuracy: 0.8188 - val_loss: 0.4718 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.47117\n",
      "Epoch 126/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4721 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.47117 to 0.47112, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/126-0.4711.hdf5\n",
      "Epoch 127/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4721 - accuracy: 0.8186 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.47112\n",
      "Epoch 128/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.47112\n",
      "Epoch 129/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4723 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.47112\n",
      "Epoch 130/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4721 - accuracy: 0.8186 - val_loss: 0.4714 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.47112\n",
      "Epoch 131/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4721 - accuracy: 0.8187 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.47112\n",
      "Epoch 132/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4721 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.47112 to 0.47110, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/132-0.4711.hdf5\n",
      "Epoch 133/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4713 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.47110\n",
      "Epoch 134/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.47110 to 0.47105, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/134-0.4711.hdf5\n",
      "Epoch 135/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.47105\n",
      "Epoch 136/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4721 - accuracy: 0.8187 - val_loss: 0.4713 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.47105\n",
      "Epoch 137/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4720 - accuracy: 0.8185 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.47105\n",
      "Epoch 138/200\n",
      "123085/123085 [==============================] - 4s 30us/step - loss: 0.4720 - accuracy: 0.8186 - val_loss: 0.4712 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.47105\n",
      "Epoch 139/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4712 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.47105\n",
      "Epoch 140/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4719 - accuracy: 0.8189 - val_loss: 0.4716 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.47105\n",
      "Epoch 141/200\n",
      "123085/123085 [==============================] - 4s 33us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4714 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.47105\n",
      "Epoch 142/200\n",
      "123085/123085 [==============================] - 4s 31us/step - loss: 0.4719 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.47105\n",
      "Epoch 143/200\n",
      "123085/123085 [==============================] - 4s 29us/step - loss: 0.4721 - accuracy: 0.8188 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.47105\n",
      "Epoch 144/200\n",
      "123085/123085 [==============================] - 4s 36us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.47105\n",
      "Epoch 145/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4720 - accuracy: 0.8188 - val_loss: 0.4714 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.47105\n",
      "Epoch 146/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4715 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.47105\n",
      "Epoch 147/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4710 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.47105 to 0.47104, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/147-0.4710.hdf5\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.47104\n",
      "Epoch 149/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4713 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.47104\n",
      "Epoch 150/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4719 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.47104\n",
      "Epoch 151/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4719 - accuracy: 0.8189 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.47104\n",
      "Epoch 152/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4720 - accuracy: 0.8188 - val_loss: 0.4715 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.47104\n",
      "Epoch 153/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4721 - accuracy: 0.8190 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.47104\n",
      "Epoch 154/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.47104\n",
      "Epoch 155/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4718 - accuracy: 0.8187 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.47104\n",
      "Epoch 156/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4718 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.47104\n",
      "Epoch 157/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4720 - accuracy: 0.8188 - val_loss: 0.4710 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.47104 to 0.47100, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/157-0.4710.hdf5\n",
      "Epoch 158/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4720 - accuracy: 0.8186 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.47100\n",
      "Epoch 159/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4719 - accuracy: 0.8187 - val_loss: 0.4713 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.47100\n",
      "Epoch 160/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.47100\n",
      "Epoch 161/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4720 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.47100\n",
      "Epoch 162/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4719 - accuracy: 0.8187 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.47100\n",
      "Epoch 163/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4710 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.47100\n",
      "Epoch 164/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4721 - accuracy: 0.8185 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.47100\n",
      "Epoch 165/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4717 - accuracy: 0.8188 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.47100\n",
      "Epoch 166/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4717 - accuracy: 0.8188 - val_loss: 0.4715 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.47100\n",
      "Epoch 167/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8197\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.47100\n",
      "Epoch 168/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4715 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.47100\n",
      "Epoch 169/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4717 - accuracy: 0.8189 - val_loss: 0.4710 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.47100\n",
      "Epoch 170/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4717 - accuracy: 0.8188 - val_loss: 0.4712 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.47100\n",
      "Epoch 171/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4718 - accuracy: 0.8187 - val_loss: 0.4709 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.47100 to 0.47093, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/171-0.4709.hdf5\n",
      "Epoch 172/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4721 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.47093\n",
      "Epoch 173/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.47093\n",
      "Epoch 174/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.47093\n",
      "Epoch 175/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4716 - accuracy: 0.8190 - val_loss: 0.4713 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.47093\n",
      "Epoch 176/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4720 - accuracy: 0.8187 - val_loss: 0.4712 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.47093\n",
      "Epoch 177/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4717 - accuracy: 0.8187 - val_loss: 0.4710 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.47093\n",
      "Epoch 178/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4717 - accuracy: 0.8188 - val_loss: 0.4710 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.47093\n",
      "Epoch 179/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4716 - accuracy: 0.8189 - val_loss: 0.4709 - val_accuracy: 0.8197\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.47093 to 0.47091, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/179-0.4709.hdf5\n",
      "Epoch 180/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4720 - accuracy: 0.8188 - val_loss: 0.4712 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.47091\n",
      "Epoch 181/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4714 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.47091\n",
      "Epoch 182/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4717 - accuracy: 0.8189 - val_loss: 0.4712 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.47091\n",
      "Epoch 183/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4719 - accuracy: 0.8188 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.47091\n",
      "Epoch 184/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4715 - accuracy: 0.8190 - val_loss: 0.4710 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.47091\n",
      "Epoch 185/200\n",
      "123085/123085 [==============================] - 5s 40us/step - loss: 0.4717 - accuracy: 0.8189 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.47091\n",
      "Epoch 186/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4718 - accuracy: 0.8187 - val_loss: 0.4711 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.47091\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4717 - accuracy: 0.8188 - val_loss: 0.4709 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.47091\n",
      "Epoch 188/200\n",
      "123085/123085 [==============================] - 5s 41us/step - loss: 0.4716 - accuracy: 0.8188 - val_loss: 0.4710 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.47091\n",
      "Epoch 189/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4709 - val_accuracy: 0.8197\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.47091 to 0.47091, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/189-0.4709.hdf5\n",
      "Epoch 190/200\n",
      "123085/123085 [==============================] - 4s 34us/step - loss: 0.4715 - accuracy: 0.8189 - val_loss: 0.4707 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.47091 to 0.47069, saving model to /home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/190-0.4707.hdf5\n",
      "Epoch 191/200\n",
      "123085/123085 [==============================] - 5s 43us/step - loss: 0.4717 - accuracy: 0.8190 - val_loss: 0.4712 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.47069\n",
      "Epoch 192/200\n",
      "123085/123085 [==============================] - 5s 43us/step - loss: 0.4717 - accuracy: 0.8188 - val_loss: 0.4710 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.47069\n",
      "Epoch 193/200\n",
      "123085/123085 [==============================] - 5s 42us/step - loss: 0.4716 - accuracy: 0.8188 - val_loss: 0.4709 - val_accuracy: 0.8194\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.47069\n",
      "Epoch 194/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4709 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.47069\n",
      "Epoch 195/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4717 - accuracy: 0.8189 - val_loss: 0.4713 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.47069\n",
      "Epoch 196/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4712 - val_accuracy: 0.8192\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.47069\n",
      "Epoch 197/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4719 - accuracy: 0.8189 - val_loss: 0.4714 - val_accuracy: 0.8195\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.47069\n",
      "Epoch 198/200\n",
      "123085/123085 [==============================] - 5s 38us/step - loss: 0.4718 - accuracy: 0.8189 - val_loss: 0.4713 - val_accuracy: 0.8198\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.47069\n",
      "Epoch 199/200\n",
      "123085/123085 [==============================] - 5s 39us/step - loss: 0.4718 - accuracy: 0.8188 - val_loss: 0.4711 - val_accuracy: 0.8196\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.47069\n",
      "Epoch 200/200\n",
      "123085/123085 [==============================] - 5s 37us/step - loss: 0.4717 - accuracy: 0.8189 - val_loss: 0.4711 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.47069\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X,train_y,epochs=200,batch_size=128,verbose=1,validation_data=[val_X,val_y],callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_best = load_model('/home/ubuntu/gangmin/tsvt/multimodal/MLP_M_models/97-0.4714.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_best.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1756767 ],\n",
       "       [0.17564765],\n",
       "       [0.17605504],\n",
       "       ...,\n",
       "       [0.22133231],\n",
       "       [1.        ],\n",
       "       [0.38906893]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros(len(y_predict))\n",
    "for i,v in enumerate(y_predict):\n",
    "    if v[0] >= 0.5:\n",
    "        result[i] = 1\n",
    "    else:\n",
    "        result[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.7333333333333333, recall : 0.0035894925762767174, f1 : 0.007144016885858094, accuracy : 0.17105352341790742\n"
     ]
    }
   ],
   "source": [
    "average = [0,0,0,0,0]\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "\n",
    "for i,v in enumerate(result):\n",
    "    if result[i] ==1 and test_y[i]==1:\n",
    "        TP+=1\n",
    "    elif result[i] ==1 and test_y[i]==0:\n",
    "        FP+=1\n",
    "    elif result[i] ==0 and test_y[i]==1:\n",
    "        TN+=1\n",
    "    else:\n",
    "        FN+=1\n",
    "    \n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "accuracy = (TP+TN) / (TP+FN+FP+TN)\n",
    "\n",
    "\n",
    "f1 = (2*precision*recall / (precision + recall))\n",
    "\n",
    "print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(precision,recall,f1,accuracy))\n",
    "average[0]+= precision\n",
    "average[1] += recall\n",
    "average[2] += f1\n",
    "average[3] += accuracy\n",
    "average[4]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision : 0.7333333333333333, recall : 0.0035894925762767174, f1 : 0.007144016885858094, accuracy : 0.17105352341790742\n"
     ]
    }
   ],
   "source": [
    "print('precision : {}, recall : {}, f1 : {}, accuracy : {}'.format(average[0]/average[4],average[1]/average[4],average[2]/average[4],average[3]/average[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
